<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Adib.notes</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Adib.notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Run a Process Across EMR Nodes</title>
      <link>/posts/20250211---run-process-across-emr/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate>
      <guid>/posts/20250211---run-process-across-emr/</guid>
      <description>&lt;p&gt;When ingesting a large amount of data, we usually use a parallel processing engine for efficiency, like Spark for efficiency.&#xA;Taking data from a database with spark is relatively straightforward, however, in our situation, it happens that our target database is behind a private network and could only be reached via a bastion box.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://bucket1.is3.cloudhost.id/blog/20250211%20-%20Run%20Process%20across%20EMR/20250211-run_command_across_emr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;bootstrap-approach&#34;&gt;Bootstrap Approach&lt;/h2&gt;&#xA;&lt;p&gt;Now, one way to do it is to set up a &lt;a href=&#34;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-bootstrap.html&#34;&gt;bootstrap&lt;/a&gt; action when creating the EMR, to include installation of the VPN and to actually run it (either as a service or inside a terminal multiplexer like &lt;a href=&#34;https://github.com/tmux/tmux&#34;&gt;tmux&lt;/a&gt;).&#xA;The problem with this approach is that it will always be on. So, in case we have to connect multiple databases with different bastion box, this approach will not work.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS Community Day</title>
      <link>/posts/20241212---aws-community/</link>
      <pubDate>Sat, 23 Nov 2024 00:00:00 +0000</pubDate>
      <guid>/posts/20241212---aws-community/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bucket1.is3.cloudhost.id/blog/20241212%20-%20AWS%20Community/20241123_aws_community.jpg&#34; alt=&#34;presenter_img&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;This November, I attend the &lt;a href=&#34;https://awscommunity.id/&#34;&gt;AWS Community&lt;/a&gt; Day Indonesia in UI, Depok.&#xA;The event constitutes a main event with a main speaker presentation and some parallel short talks (about 15 minutes).&#xA;There 2 main talks, but I only remember the presentation of Mas &lt;a href=&#34;https://www.linkedin.com/in/donnieprakoso&#34;&gt;Donnie&lt;/a&gt;, one of the legendary AWS Advocates.&#xA;He talks about the evolution of computing, and how modern tools and ecosystems could fit into that.&#xA;In the end, we also see a slight demo regarding Gen AI capability, plus AWS&amp;rsquo;s new Gen AI assistant, &lt;a href=&#34;https://aws.amazon.com/q/&#34;&gt;q&lt;/a&gt;.&#xA;For me, it&amp;rsquo;s quite insightful how the relevancy of the tools depends on the business objective and context, and how from speaker&amp;rsquo;s point of view, this technology evolves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RFM Segmentation and Analysis with Python</title>
      <link>/posts/20240219---rfm-analysis-post/</link>
      <pubDate>Wed, 31 Jan 2024 00:00:00 +0000</pubDate>
      <guid>/posts/20240219---rfm-analysis-post/</guid>
      <description>&lt;p&gt;A good understanding of the customer is key to a successful business.&#xA;Not all customers are created equally. Some (like me), might want the cheapest/free offer, others perhaps willing to pay more to get a premium service, and some might still doubt taking our full offer.&#xA;Some might be happy with the product and thus keep using it, while others may be on the verge of churning due to various reasons.&#xA;Different customer needs different actions and treatments, and segmentation is one way to explore it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Minimum Actionable Insight: Providing Value as a Data Scientist</title>
      <link>/posts/20240120---hierarchy-of-needs/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>/posts/20240120---hierarchy-of-needs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bucket1.is3.cloudhost.id/blog/20240120_hierarchy_of_needs/Leonardo_Diffusion_XL_a_duck_working_as_a_data_scientist_looki_1.jpg&#34; alt=&#34;Mr. Duck working on his RFM analysis (generated with Leonardo AI)&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;I want to start by stating something not so obvious: not all company needs to add AI to their current business.&#xA;When we consider the data science hierarchy of needs, AI utilization is placed at the top of the hierarchy,&#xA;meaning its value will be visible if the other needs below it are accommodated (except of course when AI is the core business).&#xA;This is true especially if our company is just getting started, or still trying to gain traction.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cohort Analysis With Python</title>
      <link>/posts/20231120---cohort-analysis/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20231120---cohort-analysis/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bucket1.is3.cloudhost.id/blog/20231113_cohort/Leonardo_Diffusion_XL_Several_data_analysis_looking_at_cohort_0.jpg&#34; alt=&#34;Ilustration generated with Leonardo AI&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cohort analysis is one of the simple and effective tool to better understand how customer interact in business.&#xA;We can look whether the customer are coming back, or whether their value are improved over time.&#xA;A simple tools that should be on every data analytics toolbox. But first, what is a cohort?&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-cohort&#34;&gt;What is cohort?&lt;/h1&gt;&#xA;&lt;p&gt;The technical definition of cohort analysis is behavioral analytics that breaks data into relevant groups and observes how their behavior changes over time.&#xA;For example, a company might group their user based on their first registration, and observe how their interaction with the platform changes day, week, or month.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building Python Layer for AWS Lambda with Docker</title>
      <link>/posts/20230922---python-aws-layer/</link>
      <pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20230922---python-aws-layer/</guid>
      <description>&lt;p&gt;The other day, I was building something with &lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;AWS Lambda&lt;/a&gt; that requires an additional package.&#xA;Usually, AWS has provided some scientific packages such as &lt;a href=&#34;https://scikit-learn.org/&#34;&gt;scikit-learn&lt;/a&gt; and &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;pandas&lt;/a&gt; as a Layer that is ready to use.&#xA;Unfortunately, one of the packages that I need (&lt;a href=&#34;https://seaborn.pydata.org/&#34;&gt;seaborn&lt;/a&gt;) isn&amp;rsquo;t available yet, so in order to use it in my function, I need to create a Layer manually.&lt;/p&gt;&#xA;&lt;p&gt;Usually, this is pretty straightforward, all you need to do is to install the package inside a folder and zip it. The command to run it:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neo4J Graph Summit 2023</title>
      <link>/posts/20230613---neo4j-graph-summit/</link>
      <pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20230613---neo4j-graph-summit/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bucket1.is3.cloudhost.id/blog/20230613%20-%20Neo4J%20Graph%20Summit/20230613-neo4j_presenter.jpg&#34; alt=&#34;presenter_img&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Last week I got the chance to attend Graph Summit 2023 Jakarta, organized by &lt;a href=&#34;https://neo4j.com/&#34;&gt;neo4j&lt;/a&gt;.&#xA;This event discusses the power of the graph database compared to a traditional relational database in terms of complex relations and data queries.&lt;/p&gt;&#xA;&lt;p&gt;There are also several presentations regarding the real-world use case from different speakers.&lt;/p&gt;&#xA;&lt;h4 id=&#34;influencer-taxes&#34;&gt;Influencer Taxes&lt;/h4&gt;&#xA;&lt;p&gt;One that is memorable for me is from Mr. &lt;a href=&#34;https://www.linkedin.com/in/iwan-djuniardi-6b615645/&#34;&gt;Iwan Djuniardi&lt;/a&gt; about how the Directorate General of Taxes Indonesia tries to use Graph database to detect potential income of internet influencer, and thus calculating the tax.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Producer and Consumer</title>
      <link>/posts/20230613---input-output/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20230613---input-output/</guid>
      <description>&lt;p&gt;I used to learn something by passively consuming it. Be it by watching a video course, reading a book/article, or looking into tutorials. Most of the time, the knowledge will be lost as soon as I move to learn another thing.&#xA;So now, I&amp;rsquo;m trying a new thing. Whenever I want to learn something, I must produce something. So instead of passively consuming, I need to actively produce as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Models that Runs Locally</title>
      <link>/posts/20230521-local-ai/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20230521-local-ai/</guid>
      <description>&lt;p&gt;The rise of ChatGPT and other large language models is pretty fascinating in the past few months.&lt;/p&gt;&#xA;&lt;p&gt;New models are being published with larger model sizes and data, claiming to make an improvement from before.&lt;/p&gt;&#xA;&lt;p&gt;Apart from some serious debate on the potential danger of the technology, it surely opens new ways for us to do the things we used to do.&lt;/p&gt;&#xA;&lt;p&gt;Since some models are too expensive to run just for fun, I look and tried several models that could be run locally on my computer so I could build something interesting.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Simple Backup with Borgmatic</title>
      <link>/posts/20221001-backup-with-borgmatic/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      <guid>/posts/20221001-backup-with-borgmatic/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m a self-hosted person, I own a VPS and have installed some applications that I use in my day-to-day activities.&#xA;Those apps (like chat server, using &lt;a href=&#34;https://matrix.org/&#34;&gt;Matrix&lt;/a&gt;) are becoming a part of my life, and losing the data that&amp;rsquo;s been there will be disastrous for me.&#xA;Hence, backup is a must thing to do.&lt;/p&gt;&#xA;&lt;p&gt;Doing backup isn&amp;rsquo;t that hard, especially if we use the right tools.&#xA;For the past few years, I&amp;rsquo;ve been using &lt;a href=&#34;https://www.borgbackup.org/&#34;&gt;borg&lt;/a&gt; as a tool for doing backup of all my computer-related data. It&amp;rsquo;s a simple and easy-to-use tool. And combine with &lt;a href=&#34;https://torsion.org/borgmatic/&#34;&gt;borgmatic&lt;/a&gt;, a program on top of borg to make the backup process even easier, backing up a whole data, both from a database and from the file, is as simple as running one command. Borgmatic use a configuration file to do the whole process. Here is my simple configuration that I used on regular basis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Significance Test</title>
      <link>/posts/20220620-significance-test/</link>
      <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
      <guid>/posts/20220620-significance-test/</guid>
      <description>&lt;p&gt;The main idea is we need to know whether this distribution is more likely to happen from another distribution with a level of p. So w need three things:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The first distribution (base) and its parameter&lt;/li&gt;&#xA;&lt;li&gt;The second distribution (comparator) and its parameter&lt;/li&gt;&#xA;&lt;li&gt;A limit/threshold for which we could safely say this is different.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;the-z---test&#34;&gt;The Z - Test&lt;/h3&gt;&#xA;&lt;p&gt;The T-test is for small use case ≤ 30, whereas the z-test is for the normal case. Forget about the T-test. The condition for the T-test:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Get Modified Files Within Two Snapshot</title>
      <link>/posts/20220602-get-modified-files-within-two-snapshot/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate>
      <guid>/posts/20220602-get-modified-files-within-two-snapshot/</guid>
      <description>&lt;p&gt;To make my blogging habit a little bit easier, I create a tool to easily convert my jupyter notebooks to markdown that could be parsed into &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;, called &lt;a href=&#34;https://github.com/adibPr/pynote2mds3/&#34;&gt;pynote2mds3&lt;/a&gt; that use &lt;code&gt;nbconvert&lt;/code&gt; to convert and upload any image into S3. However, I soon find out that I need to manually run this command for each of my new posts and I kind of looking for a way to automate that. The solution is using &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installing libolm From Source</title>
      <link>/posts/08-installing-libolm-from-source/</link>
      <pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/posts/08-installing-libolm-from-source/</guid>
      <description>&lt;p&gt;I stumble upon this great tool called &lt;a href=&#34;https://github.com/8go/matrix-commander&#34;&gt;matrix-commander&lt;/a&gt; that I think is the simplest way to programmatically interact with your &lt;a href=&#34;https://matrix.org/&#34;&gt;Matrix&lt;/a&gt; server.&#xA;I&amp;rsquo;m using these tools in order to send notifications from my server to my matrix room whenever something interesting happens (i.e when my backup is done, or when someone login to my server).&#xA;It is based on matrix-nio, and only a large single file python.&#xA;But I found one of the dependencies, &lt;a href=&#34;https://gitlab.matrix.org/matrix-org/olm&#34;&gt;libolm&lt;/a&gt;, is quite difficult to install (especially in my raspberry pi).&#xA;They do have a package in pip, but it&amp;rsquo;s only for python version 2.&#xA;Here is what I do to build this library from source.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Shortcut to Capture Ideas</title>
      <link>/posts/shortcut_text/</link>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
      <guid>/posts/shortcut_text/</guid>
      <description>&lt;p&gt;One common theme from the majority of productivity articles/books that I read is to never let use your brain to store information.&#xA;Use it to generate new ideas, to solve a problem, to think.&lt;/p&gt;&#xA;&lt;p&gt;But here is the thing: Sometimes when you are in a state of deep work, focusing on a task at hand, you might suddenly remember other tasks that you need to do later, or you might get an idea for other things that might not be related to your current task.&#xA;You don&amp;rsquo;t want to break down from your deep work state, but you also don&amp;rsquo;t want to store those to-do/new information in your brain that might be forgotten 30 minutes later.&#xA;For these, you need a system that could allow you to store those sudden information easily and quickly.&#xA;I personally, use a text editor.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux VPN via PPTP dari Terminal</title>
      <link>/posts/oldpost/linux-vpn-via-pptp-dari-terminal/</link>
      <pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate>
      <guid>/posts/oldpost/linux-vpn-via-pptp-dari-terminal/</guid>
      <description>&lt;p&gt;Sebagai salah satu cara untuk terhubung dengan &lt;em&gt;resource&lt;/em&gt; yang ada di kantor ketika kita berada diluar (&lt;em&gt;remote&lt;/em&gt;) adalah dengan menggunakan VPN.&#xA;Ada beberapa jenis VPN, seperti openvpn dan pptp.&#xA;Kali ini saya akan membahas proses koneksi VPN menggunakan PPTP di linux melalui &lt;em&gt;command line&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Langkahnya adalah :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Memeriksa file yang dibutuhkan&lt;/li&gt;&#xA;&lt;li&gt;Membuat file konfigurasi&lt;/li&gt;&#xA;&lt;li&gt;Membuat koneksi&lt;/li&gt;&#xA;&lt;li&gt;Set default routing&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;1-_requirements_&#34;&gt;1. &lt;em&gt;Requirements&lt;/em&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Untuk dapat terhubung melalui VPN PPTP, ada 3 hal yang harus dimiliki, yakni:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
