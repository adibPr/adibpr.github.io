<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deeplearning on Adib.notes</title>
    <link>/tags/deeplearning/</link>
    <description>Recent content in Deeplearning on Adib.notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 May 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/deeplearning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Models that Runs Locally</title>
      <link>/posts/20230521-local-ai/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      <guid>/posts/20230521-local-ai/</guid>
      <description>The rise of ChatGPT and other large language models is pretty fascinating in the past few months.&#xA;New models are being published with larger model sizes and data, claiming to make an improvement from before.&#xA;Apart from some serious debate on the potential danger of the technology, it surely opens new ways for us to do the things we used to do.&#xA;Since some models are too expensive to run just for fun, I look and tried several models that could be run locally on my computer so I could build something interesting.</description>
    </item>
  </channel>
</rss>
